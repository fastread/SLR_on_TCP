ID,Document Title,Abstract,Year,PDF Link,Prioritization goal,Data type,Information used,Method
45,A selective software testing method based on priorities assigned to functional modules,"As software systems have been introduced to many advanced applications, the size of software systems increases so much. Simultaneously, the lifetime of software systems becomes very small and thus their development is required within a relatively short period. We propose a novel selective software testing method that aims to attain the requirement of short period development. The proposed method consists of 3 steps: assign priorities to functional modules (Step 1), derive a test specification (Step 2), and construct a test plan (Step 3) according to the priorities. In Step 1, for development of functional modules, we select both product and process properties to calculate priorities. Then, in Step 2, we generate detailed test items for each module according to its priority. Finally, in Step 3, we manage test resources including time and developer's skill to attain the requirement. As a result of experimental application, we can show the superiority of the proposed testing method compared to the conventional testing method.",2001,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=990028,fault detection rate,real faults,source code,unsupervised
62,Elimination of crucial faults by a new selective testing method,"Recent software systems contain a lot of functions to provide various services. According to this tendency, software testing becomes more difficult than before and cost of testing increases so much, since many test items are required. In this paper we propose and discuss such a new selective software testing method that is constructed from previous testing method by simplifying testing specification. We have presented, in the previous work, a selective testing method to perform highly efficient software testing. The selective testing method has introduced an idea of functional priority testing and generated test items according to their functional priorities. Important functions with high priorities are tested in detail, and functions with low priorities are tested less intensively. As a result, additional cost for generating testing instructions becomes relatively high. In this paper in order to reduce its cost, we change the way of giving information, with respect to priorities. The new method gives the priority only rather than generating testing instructions to each test item, which makes the testing method quite simple and results in cost reduction. Except for this change, the new method is essentially the same as the previous method. We applied this new method to actual development of software tool and evaluated its effectiveness. From the result of the application experiment, we confirmed that many crucial faults can be detected by using the proposed method.",2002,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1166937,fault detection rate,real faults,source code,unsupervised
136,Compatibility and Regression Testing of COTS-Component-Based Software,"Software engineers frequently update COTS components integrated in component-based systems, and can often chose among many candidates produced by different vendors. This paper tackles both the problem of quickly identifying components that are syntactically compatible with the interface specifications, but badly integrate in target systems, and the problem of automatically generating regression test suites. The technique proposed in this paper to automatically generate compatibility and prioritized test suites is based on behavioral models that represent component interactions, and are automatically generated while executing the original test suites on previous versions of target systems.",2007,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4222571,fault detection rate,injected faults,source code,unsupervised
147,Prioritizing Coverage-Oriented Testing Process - An Adaptive-Learning-Based Approach and Case Study,"This paper proposes a graph-model-based approach to prioritizing the test process. Tests are ranked according to their preference degrees which are determined indirectly, i.e., through classifying the events. To construct the groups of events, unsupervised neural network is trained by adaptive competitive learning algorithm. A case study demonstrates and validates the approach.",2007,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4291124,coverage,no fault or failure,source code,search-based
205,Building Prioritized Pairwise Interaction Test Suites with Ant Colony Optimization,"Interaction testing offers a stable cost-benefit ratio in identifying faults. But in many testing scenarios, the entire test suite cannot be fully executed due to limited time or cost. In these situations, it is essential to take the importance of interactions into account and prioritize these tests. To tackle this issue, the biased covering array is proposed and the Weighted Density Algorithm (WDA) is developed. To find a better solution, in this paper we adopt ant colony optimization (ACO) to build this prioritized pairwise interaction test suite (PITS). In our research, we propose four concrete test generation algorithms based on Ant System, Ant System with Elitist, Ant Colony System and Max-Min Ant System respectively. We also implement these algorithms and apply them to two typical inputs and report experimental results. The results show the effectiveness of these algorithms.",2009,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5381411,coverage,no fault or failure,source code,search-based
225,Prioritized Test Generation Strategy for Pair-Wise Testing,"Pair-wise testing is widely used to detect faults in software systems. In many applications where pair-wise testing is needed, the whole test set can not be run completely due to time or budget constraints. In these situations, it is essential to prioritize the tests. In this paper, we drive weight for each value of each parameter, and adapt UWA algorithm to generate an ordered pair-wise coverage test suite. UWA algorithm is to accord weights set for each value of each parameter of the system, then produce ordered pair-wise coverage test set for having generated but unordered one. Finally, a greedy algorithm is adopted to prioritize generated pair-wise coverage test set with driven weights, so that whenever the testing is interrupted, interactions deemed, most important are tested.",2009,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368244,weights,no fault or failure,source code,greedy
226,Prioritizing component compatibility tests via user preferences,"Many software systems rely on third-party components during their build process. Because the components are constantly evolving, quality assurance demands that developers perform compatibility testing to ensure that their software systems build correctly over all deployable combinations of component versions, also called configurations. However, large software systems can have many configurations, and compatibility testing is often time and resource constrained. We present a prioritization mechanism that enhances compatibility testing by examining the ldquomost importantrdquo configurations first, while distributing the work over a cluster of computers. We evaluate our new approach on two large scientific middleware systems and examine tradeoffs between the new prioritization approach and a previously developed lowest-cost-configuration-first approach.",2009,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5306357,failure detection rate,real failures,human input,greedy
246,A source-based risk analysis approach for software test optimization,"In this paper we introduce our proposed technique for software component test prioritization and optimization which is based on a source-code based risk analysis. Software test is one of the most critical steps in the software development. Considering that the time and human resources of a software project are limited, software test should be scheduled and planned very carefully. In this paper we introduce a classification approach that provides the developers with a risk model of the application which is specifically designed to assist the testing process by identifying the most important components and their corresponding test effort estimation. We designed an analyser tool to apply our technique to a test software project and we presented the results in this paper.",2010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485639,fault detection rate,no fault or failure,source code,greedy
254,Constructing Prioritized Interaction Test Suite with Interaction Relationship,"Interaction testing has addressed some issues on how to select a small subset of test cases. In many systems where interaction testing is needed, the entire test suite is not executed because of time or budget constraints. It is important to prioritize the test cases in these situations. On the other hand, there are not always interactions among any factors in real systems. Moreover, some factors may need N-way (N&gt;2) testing since there is a closer relationship among them. We present a model for prioritized interaction testing with interaction relationship and propose a greedy algorithm for generating variable strength covering arrays with bias.",2010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459713,coverage,no fault or failure,coverage,greedy
308,Calculating Prioritized Interaction Test Sets with Constraints Using Binary Decision Diagrams,"Combinatorial interaction testing has become an established technique to systematically determine test sets for highly-configurable software systems. The generation of minimal test sets that fullfill the demanded coverage criteria is an NP-complete problem. Constraint handling and integrated test case prioritization, features necessary for practical use, further complicate the problem. We present a novel algorithm that exploits our observation that the combinatorial interaction testing problem with constraints can be modelled as a single propositional logic formula. Our test set calculation algorithm uses binary decision diagrams as efficient data structure for this formula. The algorithm supports constraints and prioritization. Our evaluation results prove its cost effectiveness. For many benchmark problems the algorithm calculates the best results compared to other greedy approaches.",2011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5954420,weight coverage,no fault or failure,weights,greedy
311,Change Sensitivity Based Prioritization for Audit Testing of Webservice Compositions,"Modern software systems have often the form of Web service compositions. They take advantage of the availability of a variety of external Web services to provide rich and complex functionalities, obtained as the integration of external services. However, Web services change at a fast pace and while syntactic changes are easily detected as interface incompatibilities, other more subtle changes are harder to detect and may give raise to faults. They occur when the interface is compatible with the composition, but the semantics of the service response has changed. This typically involves undocumented or implicit aspects of the service interface. Audit testing of services is the process by which the service integrator makes sure that the service composition continues to work properly with the new versions of the integrated services. Audit testing of services is conducted under strict (sometimes extreme) time and budget constraints. Hence, prioritizing the audit test cases so as to execute the most important ones first becomes of fundamental importance. We propose a test case prioritization method specifically tailored for audit testing of services. Our method is based on the idea that the most important test cases are those that have the highest sensitivity to changes injected into the service responses (mutations). In particular, we consider only changes that do not violate the explicit contract with the service (i.e., the WSDL), but may violate the implicit assumptions made by the service integrator.",2011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5954434,fault detection rate,injected faults,history,"greedy, change sensitivity, history-based"
315,"CRANE: Failure Prediction, Change Analysis and Test Prioritization in Practice -- Experiences from Windows","Building large software systems is difficult. Maintaining large systems is equally hard. Making post-release changes requires not only thorough understanding of the architecture of a software component about to be changed but also its dependencies and interactions with other components in the system. Testing such changes in reasonable time and at a reasonable cost is a difficult problem as infinitely many test cases can be executed for any modification. It is important to obtain a risk assessment of impact of such post-release change fixes. Further, testing of such changes is complicated by the fact that they are applicable to hundreds of millions of users, even the smallest mistakes can translate to a very costly failure and re-work. There has been significant amount of research in the software engineering community on failure prediction, change analysis and test prioritization. Unfortunately, there is little evidence on the use of these techniques in day-to-day software development in industry. In this paper, we present our experiences with CRANE: a failure prediction, change risk analysis and test prioritization system at Microsoft Corporation that leverages existing research for the development and maintenance of Windows Vista. We describe the design of CRANE, validation of its useful-ness and effectiveness in practice and our learnings to help enable other organizations to implement similar tools and practices in their environment.",2011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5770625,failure detection rate,no fault or failure,"source code, change, history",greedy
316,Critical component analyzer __?? A novel test prioritization framework for component based real time systems,"Component based software development system is composed of many components and it uses the reusable components as the building blocks for constructing the complex software system. The major challenges in CBS are testing component dependency that is; it is a tricky task to test each and every component for each possible input data which will lead to exhaustive testing. To reduce the cost, the industries are following some stopping criteria and release the product to the customer side. These stopping criteria will at times lead to skipping up of some of the components from rigorous testing. This will lead to hazardous side effects such as loss in terms of revenue, human life and resources. This insight leads to the need to identify critical components which have the higher dependability measure in terms of functionality and receives higher priority in testing with rigorous test procedures. Hence, this paper proposes a novel method for identifying the critical components from the Software under Test (SUT) and prioritizes them for testing with at most care based on various dependency metrics and measures among the components with the help of Component Execution Sequence Graph (CESG).",2011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6140684,fault detection rate,injected faults,dependency data from byte code,greedy
322,Developing a Single Model and Test Prioritization Strategies for Event-Driven Software,"Event-Driven Software (EDS) can change state based on incoming events; common examples are GUI and Web applications. These EDSs pose a challenge to testing because there are a large number of possible event sequences that users can invoke through a user interface. While valuable contributions have been made for testing these two subclasses of EDS, such efforts have been disjoint. This work provides the first single model that is generic enough to study GUI and Web applications together. In this paper, we use the model to define generic prioritization criteria that are applicable to both GUI and Web applications. Our ultimate goal is to evolve the model and use it to develop a unified theory of how all EDS should be tested. An empirical study reveals that the GUI and Web-based applications, when recast using the new model, show similar behavior. For example, a criterion that gives priority to all pairs of event interactions did well for GUI and Web applications; another criterion that gives priority to the smallest number of parameter value settings did poorly for both. These results reinforce our belief that these two subclasses of applications should be modeled and studied together.",2011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401169,fault detection rate,injected faults,metrics coverage,greedy
328,Goal-Oriented Test Case Selection and Prioritization for Product Line Feature Models,"The software product line engineering paradigm is amongst the widely used means for capturing and handling the commonalities and variabilities of the many applications of a target domain. The large number of possible products and complex interactions between software product line features makes the effective testing of them a challenge. To conquer the time and space complexity involved with testing a product line, an intuitive approach is the reduction of the test space. In this paper, we propose an approach to reduce the product line test space. We introduce a goal-oriented approach for the selection of the most desirable features from the product line. Such an approach allows us to identify the features that are more important and need to be tested more comprehensively from the perspective of the domain stakeholders. The more important features and the configurations that contain them will be given priority over the less important configurations, hence providing a hybrid test case reduction and prioritization strategy for testing software product lines.",2011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5945249,fault detection rate,no fault or failure,feature model,unsupervised
375,Dynamic Fault Visualization Tool for Fault-based Testing and Prioritization,"Fault-based testing has been proven to be a cost effective testing technique for software logics and rules expressed in Boolean expressions. It can guarantee the elimination of common faults without exhaustive testing. However, average software testing practitioners may not have in-depth knowledge on Boolean algebra and complex logic derivations required to apply existing fault-based testing techniques. In this paper, a dynamic fault visualization tool has been proposed. This tool allows its user to visualize fault-based testing and prioritize test inputs with a simple greedy method. The performance evaluation of this tool has been done on Boolean expressions extracted from a real life aviation tool. The results show that it can achieve significant performance improvements compared to ordinary sequential order test execution and existing static technique. The proposed visualization tool could also identify possible faults to guide the debugging process.",2012,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6516370,7 common types of fault detection rate,injected faults,fault coverage,greedy
509,Applying Ant Colony Optimization in software testing to generate prioritized optimal path and test data,"Software testing is one of the most important parts of software development lifecycle. Among various types of software testing approaches structural testing is widely used. Structural testing can be improved largely by traversing all possible code paths of the software. Genetic algorithm is the most used search technique to automate path testing and test case generation. Recently, different novel search based optimization techniques such as Ant Colony Optimization (ACO), Artificial Bee Colony (ABC), Artificial Immune System (AIS), Particle Swarm Optimization (PSO) have been applied to generate optimal path to complete software coverage. In this paper, ant colony optimization (ACO) based algorithm has been proposed which will generate set of optimal paths and prioritize the paths. Additionally, the approach generates test data sequence within the domain to use as inputs of the generated paths. Proposed approach guarantees full software coverage with minimum redundancy. This paper also demonstrates the proposed approach applying it in a program module.",2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307500,coverage,no fault or failure,source code,search-based
541,Prioritization and ranking of ERP testing components,"Software Testing is one of the most important activities but more often than not attracts less attention than it deserves in software development and implementation. It often takes twenty to sometimes even more than fifty percent of the total software development time. Enterprise Resource Planning (ERP) Systems provide synergy by integrating all operations of an enterprise. So implementation of ERP systems need even more rigorous testing than that employed in stand-alone software development. Software testing is a well-researched area but software testing as employed on ERP systems albeit is droughted with respect to research. This research paper is an extension of the patent by Kapur et al.[8] that identified the ERP Testing Components to measure ERP testing efficiency. Here, the ERP Testing Components have been accumulated and categorized under five heads. Thereafter, these testing components have been prioritized and ranked with the help of Analytic Hierarchy Process (AHP), as given by Saaty [17].",2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359245,weights,no fault or failure,metrics for ERP testing,greedy
542,Prioritization of test scenarios using hybrid genetic algorithm based on UML activity diagram,"Software testing is an essential part of the SDLC(Software Development Life Cycle). Test scenarios are used to derive test cases for model based testing. However, with the software rapidly growing in size and complexity, the cost of software will be too high if we want to test all the test cases. So this paper presents an approach using Hybrid Genetic Algorithm(HGA) to prioritize test scenarios, which improves efficiency and reduces cost as well. The algorithm combines Genetic Algorithm(GA) with Particle Swarm Optimization(PSO) algorithm and uses Local Search Strategy to update the local and global best information of the PSO. The proposed algorithm can prioritize test scenarios so as to find a critical scenario. Finally, the proposed method is applied to several typical UML activity diagrams, and compared with the Simple Genetic Algorithm(SGA). The experimental results show that the proposed method not only prioritizes test scenarios, but also improves the efficiency, and further saves effort, time as well as cost.",2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339189,fitness,no fault or failure, control flow graph,search-based
571,A hybrid approach for test case prioritization and optimization using meta-heuristics techniques,"Software testing is a very crucial and important phase for (SDLC) software development life cycle. Software is being tested on its effectiveness for generating good quality software. Regression testing is done by considering the constraints of resources and in this phase optimization of test suite is very important and crucial. This paper mainly aims to make use of hybrid approach of meta-heuristics, It comprises of two algorithms first is genetic algorithm and second is particle swarm optimization. In addition to algorithm the comparison of proposed algorithm hybrid GA_PSO with other optimization algorithms are been done. To validate the research Average Percentage Fault Detection (APFD) metric is used for comparison and fitness evaluation of the proposed algorithm.",2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975319,fault detection rate,injected faults,fault coverage,search-based
653,Using memetic algorithms for test case prioritization in model based software testing,"Building high quality software is one of the main goals in software industry. Software testing is a critical step in confirming the quality of software. Testing is an expensive activity because it consumes about 30% to 50% of all software developing cost. Today much research has been done in generating and prioritizing tests. First, tester should find the most important and critical path in software. They can reduce cost by finding errors and preventing to propagate it in design step. In this paper, a model based testing method is introduced. This method can prioritize tests using activity diagram, control flow graph, genetic and memetic algorithm. Different version of memetic algorithm has been made by stochastic local search, randomize iterative improvement, hill climbing and simulated annealing algorithms. The results show that the using local search methods with genetic algorithm (GA) provide efficiency and produce competitive results in comparison with GA.",2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482129,fitness,no fault or failure,control flow graph,search-based
704,Improving the Cooperation of Fuzzing and Symbolic Execution by Test-cases Prioritizing,"Nowadays much attention is paid to the threat of vulnerabilities on the software security. Fuzzing and symbolic execution, complementary to each other, are two effective techniques in software testing. In this paper, we develop the prototype called FAS(Fuzzing and Symbolic) for software testing under both fuzzing and symbolic execution. In our method, the test cases are prioritized through deep-oriented strategy and large-distance-first strategy, in order to get a higher path-coverage with the condition of limited resource.",2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288548,coverage,no fault or failure,source code,search-based
723,Test Optimization from Release Insights: An Analytical Hierarchy Approach,"Software Testing is an essential aspect to ensure software quality, reliability and consistent user experience. Digital applications such as mobile app usually follow rapid software delivery which consists of various releases. It typically uses insights from the development data such as defects, test logs for test execution optimization. Once the application is released and deployed, there is rich availability of untapped heterogeneous data which can also be effectively utilized for the next release test execution optimization. The data from the release includes direct customer feedback, application monitoring data such as user behavioral traces, device usages, release logs. In this position paper, we discuss about the various data sources and the multiple insights which can be derived from them. We also propose a framework which uses Analytical Hierarchy Process to prioritize the tests based on these insights available from the release data. The framework also recommends the prioritized and missed device configurations for next release test planning.",2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7967947,impact,no fault or failure,"release insights, human input",unsupervised
729,TITAN: Test Suite Optimization for Highly Configurable Software,"Exhaustive testing of highly configurable software developed in continuous integration is rarely feasible in practice due to the configuration space of exponential size on the one hand, and strict time constraints on the other. This entails using selective testing techniques to determine the most failure-inducing test cases, conforming to highly-constrained time budget. These challenges have been well recognized by researchers, such that many different techniques have been proposed. In practice, however, there is a lack of efficient tools able to reduce high testing effort, without compromising software quality. In this paper we propose a test suite optimization technology TITAN, which increases the time-and cost-efficiency of testing highly configurable software developed in continuous integration. The technology implements practical test prioritization and minimization techniques, and provides test traceability and visualization for improving the quality of testing. We present the TITAN tool and discuss a set of methodological and technological challenges we have faced during TITAN development. We evaluate TITAN in testing of Cisco's highly configurable software with frequent high quality releases, and demonstrate the benefit of the approach in such a complex industry domain.",2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7928010,fault detection rate,real faults,"requirement coverage, history",greedy
737,An Empirical Comparison of Fixed-Strength and Mixed-Strength for Interaction Coverage Based Prioritization,"Test case prioritization (TCP) plays an important role in identifying, characterizing, diagnosing, and correcting faults quickly. The TCP has been widely used to order test cases of different types, including model inputs (also called<italic>abstract test cases</italic>). Model inputs are constructed by modeling the program according to its input parameters, values, and constraints, and has been used in different testing methods, such as combinatorial interaction testing and software product line testing. The<italic>Interaction coverage-based TCP</italic>(ICTCP) uses interaction coverage information derived from the model input to order inputs. Previous studies have focused generally on the<italic>fixed-strength</italic>ICTCP, which adopts a fixed strength (<italic>i.e.</italic>, the level of parameter interactions) to support the ICTCP process. It is generally accepted that using more strengths for ICTCP,<italic>i.e.</italic>,<italic>mixed-strength</italic>ICTCP, may give better ordering than fixed-strength. To confirm whether mixed-strength is better than fixed-strength, in this paper, we report on an extensive empirical study using five real-world programs (written in C), each of which has six versions. The results of the empirical studies show that mixed-strength has better rates of interaction coverage overall than fixed-strength, but they have very similar rates of fault detection. Our results also show that fixed-strength should be used instead of the mixed-strength at the later stage of software testing. Finally, we offer some practical guidelines for testers when using interaction coverage information to prioritize model inputs, under different testing scenarios and resources.",2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8523673,fault detection rate,injected faults,input parameter model,greedy
739,Assessing Test Case Prioritization on Real Faults and Mutants,"Test Case Prioritization (TCP) is an important component of regression testing, allowing for earlier detection of faults or helping to reduce testing time and cost. While several TCP approaches exist in the research literature, a growing number of studies have evaluated them against synthetic software defects, called mutants. Hence, it is currently unclear to what extent TCP performance on mutants would be representative of the performance achieved on real faults. To answer this fundamental question, we conduct the first empirical study comparing the performance of TCP techniques applied to both real-world and mutation faults. The context of our study includes eight well-studied TCP approaches, 35k+ mutation faults, and 357 real-world faults from five Java systems in the Defects4J dataset. Our results indicate that the relative performance of the studied TCP techniques on mutants may not strongly correlate with performance on real faults, depending upon attributes of the subject programs. This suggests that, in certain contexts, the best performing technique on a set of mutants may not be the best technique in practice when applied to real faults. We also illustrate that these correlations vary for mutants generated by different operators depending on whether chosen operators reflect typical faults of a subject program. This highlights the importance, particularly for TCP, of developing mutation operators tailored for specific program domains.",2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530033,fault detection rate,"real faults, injected faults","source code, test code","greedy, search-based"
745,DevOps Improvements for Reduced Cycle Times with Integrated Test Optimizations for Continuous Integration,"DevOps, as a growing development practice that aims to enable faster development and efficient deployment of applications without compromising on quality, is often hampered by long cycle times. One contributing factor to long cycle times in DevOps is long build time. Automated testing in continuous integration is one of the build stages that is highly prone to long run-time due to software complexity and evolution, and inefficient due to unoptimized testing approaches. To be cost-effective, testing in continuous integration needs to use only a fast-running set of comprehensive tests that are able to ensure the level of quality needed for deployment to production. Known approaches use time-aware test selection methods to improve time-efficiency of continuous integration testing by providing optimized combinations and order of tests with respect to decreased run-time. However, focusing on time-efficiency as the sole criterion in DevOps often jeopardizes the quality of software deliveries. This paper proposes a technique that integrates fault-based and risk-based test selection and prioritization optimized for low run-time, to improve time-effectiveness of continuous integration testing, and thus reduce long cycle times in DevOps, without compromising on quality. The technique has been evaluated in testing of a large-scale configurable software in continuous integration, and has shown considerable improvement over industry practice with respect to time-efficiency.",2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377636,"fault detection rate, risk coverage",real faults,"change, history, risk",greedy
206,Configuration aware prioritization techniques in regression testing,"Configurable software lets users customize applications in many ways, and is becoming increasingly prevalent. Regression testing is an important but expensive way to build confidence that software changes introduce no new faults as software evolves, resulting in many attempts to improve its performance given limited resources. Whereas problems such as test selection and prioritization at the test case level have been extensively researched in the regression testing literature, they have rarely been considered for configurations, though there is evidence that we should not ignore the effects of configurations on regression testing. This research intends to provide a framework for configuration aware prioritization techniques, evaluated through empirical studies.",2009,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5071025,"fault detection rate, coverage",injected faults,"coverage, specification",greedy
252,Arranging software test cases through an optimization method,"During the software testing process, the customers would be invited to review or inspect an ongoing software product. This phase is called the __??in-plant__?_� test, often known as an __??alpha__?_� test. Typically, this test phase lasts for a very short period of time in which the software test engineers or software quality engineers rush to execute a list of software test cases in the test suite with customers. Because of the time constraint, the test cases have to be arranged in terms of test case severities, estimated test time, and customers' demands. As important as the test case arrangement is, this process is mostly performed manually by the project managers and software test engineers together. As the software systems are getting more sophisticated and complex, a greater volume of test cases have to be generated, and the manual arrangement approach may not be the most efficient way to handle this. In this paper, we propose a framework for automating the process of test case arrangement and management through an optimization method. We believe that this framework will help software test engineers facing with the challenges of prioritizing test cases.",2010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602131,"severity, customer preference",no fault or failure,"severity, user input",search-based
275,Requirement-based test case generation and prioritization,"Software release testing is a critical phase in the software development life cycle, as it validates the software against its requirements. Designing comprehensive release test cases that are driven by the software requirements remain the major success factor of the testing phase as far as the software customers are concerned. Further, availing sufficient traceability information to ensure complete coverage of requirements validation in the designed test case suite is significant to software quality assurance. In this paper, we propose a systematic mechanism to derive a set of release test cases from a set of requirements modeled with the Genetic Software Engineering (GSE) method. GSE models functional requirements with a semi-formal visual notation called Behavior Trees (BT). Our algorithm prioritizes the requirements modeled with BTs and derives a set of prioritized release test cases systematically. Additionally, our algorithm provides sufficient traceability information relating test cases to the requirements being tested. This allows for ensuring completeness of test case coverage. We also demonstrate our test case derivation mechanism through a case study.",2010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720443,requirement coverage,no fault or failure,requirement coverage,greedy
281,Taking Advantage of Service Selection: A Study on the Testing of Location-Based Web Services Through Test Case Prioritization,"Dynamic service compositions pose new verification and validation challenges such as uncertainty in service membership. Moreover, applying an entire test suite to loosely coupled services one after another in the same composition can be too rigid and restrictive. In this paper, we investigate the impact of service selection on service-centric testing techniques. Specifically, we propose to incorporate service selection in executing a test suite and develop a suite of metrics and test case prioritization techniques for the testing of location-aware services. A case study shows that a test case prioritization technique that incorporates service selection can outperform their traditional counterpart - the impact of service selection is noticeable on software engineering techniques in general and on test case prioritization techniques in particular. Further-more, we find that points-of-interest-aware techniques can be significantly more effective than input-guided techniques in terms of the number of invocations required to expose the first failure of a service composition.",2010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5552784,fault detection rate,injected faults,"location, point of interest",greedy
435,Randomizing regression tests using game theory,"As software evolves, the number of test-cases in the regression test suites continues to increase, requiring testers to prioritize their execution. Usually only a subset of the test cases is executed due to limited testing resources. This subset is often known to the developers who may try to __??game__?_� the system by committing insufficiently tested code for parts of the software that will not be tested. In this new ideas paper, we propose a novel approach for randomizing regression test scheduling, based on Stackelberg games for deployment of scarce resources. We apply this approach to randomizing test cases in such a way as to maximize the testers' expected payoff when executing the test cases. Our approach accounts for resource limitations (e.g., number of testers) and provides a probabilistic distribution for scheduling test cases. We provide an example application of our approach showcasing the idea of using Stackelberg games for randomized regression test scheduling.",2013,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693122,payoff,no fault or failure,requirement coverage,game theory
488,Test Suite Prioritization by Switching Cost,"Test suite generation and prioritization are two main research fields to improve testing efficiency. Combinatorial testing has been proven as an effective method to generate test suite for highly configurable software systems, while test suites are often prioritized by interaction coverage to detect faults as early as possible. However, for some cases, there exists reasonable cost of reconfiguring parameter settings when switching test cases in different orders. Surprisingly, only few studies paid attention to it. In this paper, by proposing greedy algorithms and graph-based algorithms, we aim to prioritize a given test suite to minimize its total switching cost. We also compare two different prioritization strategies by a series of experiments, and discuss the advantages of our prioritization strategy and the selection of prioritization techniques. The results show that prioritization by switching cost can improve testing efficiency and our prioritization strategy can produce a small test suite with a reasonably low switching cost. This prioritization can be used widely and help locate fault causing interactions. The results also suggest that when testing highly configurable software systems and no knowledge of fault detection can be used, prioritization by switching cost is a good choice to detect faults earlier.",2014,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6825648,coverage,no fault or failure,switching cost,"greedy, graph-based"
500,A novel dynamic analysis of test cases to improve testing efficiency in object-oriented systems,"In this paper, we present a series of methods to improve testing efficiency especially for regression testing from a novel view, namely dynamic analysis of test cases suitable for class testing in object-oriented systems. We mine static call graphs and dynamic call trees to represent the static features and dynamic tests of the program. By graph analysis, we present a series of methods and testing criteria to evaluate test cases from the view of code coverage. These methods improve testing efficiency for class testing from the following aspects: automation; multi-angle evaluations of test cases; improvement and management of test cases; providing different prioritization criteria and optimization criteria for regression testing to meet different testing requirements etc. What's more, they can be used in large-scale OO systems, and the test results are quantifiable.",2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490789,coverage,no fault or failure,"source code, call graph",greedy
540,Preemptive Regression Testingof Workflow-Based Web Services,"An external web service may evolve without prior notification. In the course of the regression testing of a workflow-based web service, existing test case prioritization techniques may only verify the latest service composition using the not-yet-executed test cases, overlooking high-priority test cases that have already been applied to the service composition before the evolution. In this paper, we propose Preemptive Regression Testing (PRT), an adaptive testing approach to addressing this challenge. Whenever a change in the coverage of any service artifact is detected, PRT recursively preempts the current session of regression test and creates a sub-session of the current test session to assure such lately identified changes in coverage by adjusting the execution priority of the test cases in the test suite. Then, the sub-session will resume the execution from the suspended position. PRT terminates only when each test case in the test suite has been executed at least once without any preemption activated in between any test case executions. The experimental result confirms that testing workflow-based web service in the face of such changes is very challenging; and one of the PRT-enriched techniques shows its potential to overcome the challenge.",2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6812226,fault detection rate,injected faults,"change, coverage",adaptive
552,Test case analytics: Mining test case traces to improve risk-driven testing,"In risk-driven testing, test cases are generated and/or prioritized based on different risk measures. For example, the most basic risk measure would analyze the history of the software and assigns higher risk to the test cases that used to detect bugs in the past. However, in practice, a test case may not be exactly the same as a previously failed test, but quite similar. In this study, we define a new risk measure that assigns a risk factor to a test case, if it is similar to a failing test case from history. The similarity is defined based on the execution traces of the test cases, where we define each test case as a sequence of method calls. We have evaluated our new risk measure by comparing it to a traditional risk measure (where the risk measure would be increased only if the very same test case, not a similar one, failed in the past). The results of our study, in the context of test case prioritization, on two open source projects show that our new risk measure is by far more effective in identifying failing test cases compared to the traditional risk measure.",2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070482,fault detection rate,real faults,"history, methods called by test case",history-based
578,ACO based embedded system testing using UML Activity Diagram,"This paper proposed a model-based technique for test scenario generation using Activity Diagram (AD). We transform an AD specification into an intermediate graph called Activity Interaction Graph (AIG) using the proposed parser. After that, we apply combination of BFS and DFS algorithms for generating test scenarios. Then, we apply an algorithm called ACOToTSP (Ant Colony Optimization for Test Scenarios Prioritization) algorithm on the generated test scenarios with respect to some decision and concurrent criteria, for prioritizing the test scenarios. This approach generates test scenarios according to forks, Joins, and merge point's strength in the activity diagram.",2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847997,coverage,no fault or failure,Activity Diagram,search-based
623,Neuro-fuzzy based approach to event driven software testing: A new opportunity,"Event Driven Software (EDS) testing is a very challenging task as a large number of events can be invoked by users. So far it is difficult to test all the user inputs invoked, therefore, test case prioritization is essentially required for giving more priority to test cases which reveal higher faults comparatively. We have proposed test case prioritization for EDS: as the Event Type, Interaction of Event, and Coverage of Event. Priority assigned in the proposed model uses these factors in Adaptive Neuro-Fuzzy Inference System (ANFIS) MATLAB Toolbox based on Neuro-Fuzzy logic model. Evaluation and validation will be done using Average Percentage of Fault Detection (APFD). APFD rate for prioritized sequence using the proposed Neuro-Fuzzy logic model exhibited 81% rate, whereas, non-prioritized test sequences showed70% suggesting, thereby, that after prioritization; rate of fault detection has improved considerably. Data shows that proposed Neuro-Fuzzy logic model is apt for Test Case Prioritization of EDS Testing.",2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975349,fault detection rate,injected faults,event coverage,greedy
689,Design and Implementation of Combinatorial Testing Tools,"As an effective software testing technique, combinatorial testing has been gradually applied in various types of test practice. In this case, it is necessary to provide useful combinatorial testing tools to support the application of combinatorial testing technique on industrial scenarios, as well as the academic research for combinatorial testing technique. To this end, on the basis of the research results of this group, a suite of combinatorial testing tools has been developed, whose functions include test case generation, test case optimization, and etc. For the requirements from both industrial and academic scenarios, the tools should be configurable, scalable, modular, and etc. This paper gives a brief introduction to the design and implementation of these tools. Keywords-combinatorial testing, combinatorial testing tools, test generation, test prioritization.",2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8004338,coverage,no fault or failure,combination coverage,greedy
